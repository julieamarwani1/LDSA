{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section B - Working with DataFrames and SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.1 Load the CSV file from HDFS, and call show() to verify the data is loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# New API\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.87:7077\") \\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.executor.cores\",4)\\\n",
    "        .appName(\"Julie_Rajkumar_Amarwani_Lab3_Section-B\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Old API (RDD)\n",
    "spark_context = spark_session.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = spark_session.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .csv('hdfs://192.168.2.87:9000/parking-citations.csv')\\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifying the data is loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+----------+--------+-----------+--------------+-----------------+----+----+----------+-----+--------------------+-----+------+--------------+---------------------+-----------+---------+---------+------------------+-----------------+----------------------+\n",
      "|Ticket number|          Issue Date|Issue time|Meter Id|Marked Time|RP State Plate|Plate Expiry Date| VIN|Make|Body Style|Color|            Location|Route|Agency|Violation code|Violation Description|Fine amount| Latitude|Longitude|Agency Description|Color Description|Body Style Description|\n",
      "+-------------+--------------------+----------+--------+-----------+--------------+-----------------+----+----+----------+-----+--------------------+-----+------+--------------+---------------------+-----------+---------+---------+------------------+-----------------+----------------------+\n",
      "|   1103341116|2015-12-21T00:00:...|      1251|    null|       null|            CA|           200304|null|HOND|        PA|   GY|     13147 WELBY WAY|01521|     1|        4000A1|   NO EVIDENCE OF REG|         50|    99999|    99999|              null|             null|                  null|\n",
      "|   1103700150|2015-12-21T00:00:...|      1435|    null|       null|            CA|           201512|null| GMC|        VN|   WH|       525 S MAIN ST| 1C51|     1|        4000A1|   NO EVIDENCE OF REG|         50|    99999|    99999|              null|             null|                  null|\n",
      "|   1104803000|2015-12-21T00:00:...|      2055|    null|       null|            CA|           201503|null|NISS|        PA|   BK|       200 WORLD WAY|  2R2|     2|          8939|           WHITE CURB|         58|6439997.9|1802686.4|              null|             null|                  null|\n",
      "|   1104820732|2015-12-26T00:00:...|      1515|    null|       null|            CA|             null|null|ACUR|        PA|   WH|       100 WORLD WAY| 2F11|     2|           000|               17104h|       null|6440041.1|1802686.2|              null|             null|                  null|\n",
      "|   1105461453|2015-09-15T00:00:...|       115|    null|       null|            CA|           200316|null|CHEV|        PA|   BK|  GEORGIA ST/OLYMPIC|1FB70|     1|         8069A| NO STOPPING/STANDING|         93|    99999|    99999|              null|             null|                  null|\n",
      "|   1106226590|2015-09-15T00:00:...|        19|    null|       null|            CA|           201507|null|CHEV|        VN|   GY|  SAN PEDRO S/O BOYD|1A35W|     1|        4000A1|   NO EVIDENCE OF REG|         50|    99999|    99999|              null|             null|                  null|\n",
      "|   1106500452|2015-12-17T00:00:...|      1710|    null|       null|            CA|           201605|null|MAZD|        PA|   BL|     SUNSET/ALVARADO|00217|     1|          8070| PARK IN GRID LOCK ZN|        163|    99999|    99999|              null|             null|                  null|\n",
      "|   1106500463|2015-12-17T00:00:...|      1710|    null|       null|            CA|           201602|null|TOYO|        PA|   BK|     SUNSET/ALVARADO|00217|     1|          8070| PARK IN GRID LOCK ZN|        163|    99999|    99999|              null|             null|                  null|\n",
      "|   1106506402|2015-12-22T00:00:...|       945|    null|       null|            CA|           201605|null|CHEV|        PA|   BR|      721 S WESTLAKE| 2A75|     1|        8069AA|     NO STOP/STAND AM|         93|    99999|    99999|              null|             null|                  null|\n",
      "|   1106506413|2015-12-22T00:00:...|      1100|    null|       null|            CA|           201701|null|NISS|        PA|   SI|     1159 HUNTLEY DR| 2A75|     1|        8069AA|     NO STOP/STAND AM|         93|    99999|    99999|              null|             null|                  null|\n",
      "|   1106506424|2015-12-22T00:00:...|      1100|    null|       null|            CA|           201511|null|FORD|        TR|   WH|     1159 HUNTLEY DR| 2A75|     1|        8069AA|     NO STOP/STAND AM|         93|    99999|    99999|              null|             null|                  null|\n",
      "|   1106506435|2015-12-22T00:00:...|      1105|    null|       null|            CA|           201701|null|CHRY|        PA|   GO|     1159 HUNTLEY DR| 2A75|     1|        8069AA|     NO STOP/STAND AM|         93|    99999|    99999|              null|             null|                  null|\n",
      "|   1106506446|2015-12-22T00:00:...|      1110|    null|       null|            CA|           201511|null| BMW|        PA|   BK|      1200 W MIRAMAR| 2A75|     1|        4000A1|   NO EVIDENCE OF REG|         50|    99999|    99999|              null|             null|                  null|\n",
      "|   1106549754|2015-12-15T00:00:...|       825|    null|       null|            CA|           201607|null|PTRB|        TR|   BK|           4TH/STATE| CM96|     1|         8069A| NO STOPPING/STANDING|         93|    99999|    99999|              null|             null|                  null|\n",
      "|   1107179581|2015-12-27T00:00:...|      1055|    null|       null|            CA|           201605|null|TOYO|        PA|   BK|3100 N HOLLYRIDGE DR| null|    54|         8058L|         PREF PARKING|         68|    99999|    99999|              null|             null|                  null|\n",
      "|   1107179592|2015-12-27T00:00:...|      1200|    null|       null|            CA|           201602|null|MBNZ|        PA|   BK|   3115 N BERENDO DR| null|    54|         8058L|         PREF PARKING|         68|    99999|    99999|              null|             null|                  null|\n",
      "|   1107179603|2015-12-27T00:00:...|      1400|    null|       null|            CA|           201611|null|NISS|        PA|   WH| 3100 N BEACHWOOD DR| null|    54|         8058L|         PREF PARKING|         68|    99999|    99999|              null|             null|                  null|\n",
      "|   1107539823|2015-09-16T00:00:...|      2120|    null|       null|            CA|           201502|null|NISS|        PA| null|      BLAINE/11TH PL|1FB95|     1|        4000A1|   NO EVIDENCE OF REG|         50|    99999|    99999|              null|             null|                  null|\n",
      "|   1107539834|2015-09-16T00:00:...|      1045|    null|       null|            CA|             null|null|CHEV|        PA|   BK|  1246 S FIGUEROA ST| 1L20|     1|        8069AP|     NO STOP/STAND PM|         93|    99999|    99999|              null|             null|                  null|\n",
      "|   1107780811|2015-12-22T00:00:...|      1102|    null|       null|            CA|           201606|null|HOND|        PA|   BK|       PLATA/RAMPART|  2A1|     1|         8069B|           NO PARKING|         73|    99999|    99999|              null|             null|                  null|\n",
      "+-------------+--------------------+----------+--------+-----------+--------------+-----------------+----+----+----------+-----+--------------------+-----+------+--------------+---------------------+-----------+---------+---------+------------------+-----------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_frame.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.2 Count the number of partitions in the underlying RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.3 Print the schema for the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ticket number: string (nullable = true)\n",
      " |-- Issue Date: string (nullable = true)\n",
      " |-- Issue time: string (nullable = true)\n",
      " |-- Meter Id: string (nullable = true)\n",
      " |-- Marked Time: string (nullable = true)\n",
      " |-- RP State Plate: string (nullable = true)\n",
      " |-- Plate Expiry Date: string (nullable = true)\n",
      " |-- VIN: string (nullable = true)\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Body Style: string (nullable = true)\n",
      " |-- Color: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Route: string (nullable = true)\n",
      " |-- Agency: string (nullable = true)\n",
      " |-- Violation code: string (nullable = true)\n",
      " |-- Violation Description: string (nullable = true)\n",
      " |-- Fine amount: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      " |-- Agency Description: string (nullable = true)\n",
      " |-- Color Description: string (nullable = true)\n",
      " |-- Body Style Description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_frame.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.4 Count the number of rows in the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows :  9881842\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of rows : \",data_frame.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.5 Drop the columns Agency Description, Agency, and Route."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema after deleting the above mentioned column \n",
      "\n",
      "root\n",
      " |-- Ticket number: string (nullable = true)\n",
      " |-- Issue Date: string (nullable = true)\n",
      " |-- Issue time: string (nullable = true)\n",
      " |-- Meter Id: string (nullable = true)\n",
      " |-- Marked Time: string (nullable = true)\n",
      " |-- RP State Plate: string (nullable = true)\n",
      " |-- Plate Expiry Date: string (nullable = true)\n",
      " |-- VIN: string (nullable = true)\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Body Style: string (nullable = true)\n",
      " |-- Color: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Violation code: string (nullable = true)\n",
      " |-- Violation Description: string (nullable = true)\n",
      " |-- Fine amount: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      " |-- Color Description: string (nullable = true)\n",
      " |-- Body Style Description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_frame_drop = data_frame.drop(\"Agency Description\",\"Agency\",\"Route\")\n",
    "\n",
    "print(\"Schema after deleting the above mentioned column \\n\")\n",
    "\n",
    "data_frame_drop.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.6 Find the mean fine amount (you need to convert the column to a float)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Converting to float type\n",
      "+-----------+\n",
      "|Fine amount|\n",
      "+-----------+\n",
      "|         50|\n",
      "|         50|\n",
      "|         58|\n",
      "|       null|\n",
      "|         93|\n",
      "|         50|\n",
      "|        163|\n",
      "|        163|\n",
      "|         93|\n",
      "|         93|\n",
      "+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Before Converting to float type\")\n",
    "data_frame.select('Fine amount').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Converting to Float Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ticket number: string (nullable = true)\n",
      " |-- Issue Date: string (nullable = true)\n",
      " |-- Issue time: string (nullable = true)\n",
      " |-- Meter Id: string (nullable = true)\n",
      " |-- Marked Time: string (nullable = true)\n",
      " |-- RP State Plate: string (nullable = true)\n",
      " |-- Plate Expiry Date: string (nullable = true)\n",
      " |-- VIN: string (nullable = true)\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Body Style: string (nullable = true)\n",
      " |-- Color: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Route: string (nullable = true)\n",
      " |-- Agency: string (nullable = true)\n",
      " |-- Violation code: string (nullable = true)\n",
      " |-- Violation Description: string (nullable = true)\n",
      " |-- Fine amount: float (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      " |-- Agency Description: string (nullable = true)\n",
      " |-- Color Description: string (nullable = true)\n",
      " |-- Body Style Description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import FloatType\n",
    "import pyspark.sql.functions\n",
    "\n",
    "DF_float = data_frame.withColumn(\"Fine amount\", data_frame[\"Fine amount\"].cast(FloatType()))\n",
    "\n",
    "DF_float.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Converting the column to float type.\n",
      "\n",
      "+-----------+\n",
      "|Fine amount|\n",
      "+-----------+\n",
      "|       50.0|\n",
      "|       50.0|\n",
      "|       58.0|\n",
      "|       null|\n",
      "|       93.0|\n",
      "|       50.0|\n",
      "|      163.0|\n",
      "|      163.0|\n",
      "|       93.0|\n",
      "|       93.0|\n",
      "+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"After Converting the column to float type.\\n\")\n",
    "DF_float.select('Fine amount').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean of Fine Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|avg(Fine amount)|\n",
      "+----------------+\n",
      "|70.1855354220642|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, avg\n",
    "\n",
    "DF_float.agg(avg(col(\"Fine amount\"))).show()\n",
    "#DF_float.select('Fine amount').summary().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.7 Show the top 10 most frequent vehicle makes, and their frequencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "|Make|  count|\n",
      "+----+-------+\n",
      "|TOYT|1633266|\n",
      "|HOND|1113834|\n",
      "|FORD| 860828|\n",
      "|NISS| 709250|\n",
      "|CHEV| 674422|\n",
      "| BMW| 450909|\n",
      "|MERZ| 402126|\n",
      "|VOLK| 335618|\n",
      "|HYUN| 304934|\n",
      "|DODG| 290979|\n",
      "+----+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DF_float.groupBy('Make')\\\n",
    "             .count()\\\n",
    "             .sort('count', ascending=False)\\\n",
    "             .show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.8 Let’s expand some abbreviations in the color column. Create a User Defined Function to create a new column, ‘color long’, mapping the original colors to their corresponding values in the dictionary below. If there is no key matching the original color, use the original color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|Color|Color long|\n",
      "+-----+----------+\n",
      "|   GY|      Gray|\n",
      "|   WH|     White|\n",
      "|   BK|     Black|\n",
      "|   WH|     White|\n",
      "|   BK|     Black|\n",
      "|   GY|      Gray|\n",
      "|   BL|      Blue|\n",
      "|   BK|     Black|\n",
      "|   BR|     Brown|\n",
      "|   SI|    Silver|\n",
      "|   WH|     White|\n",
      "|   GO|      Gold|\n",
      "|   BK|     Black|\n",
      "|   BK|     Black|\n",
      "|   BK|     Black|\n",
      "+-----+----------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import udf\n",
    "def color_long(shades):\n",
    "\n",
    "    COLORS = {\n",
    "    'AL':'Aluminum', 'AM':'Amber', 'BG':'Beige', 'BK':'Black',\n",
    "    'BL':'Blue', 'BN':'Brown', 'BR':'Brown', 'BZ':'Bronze',\n",
    "    'CH':'Charcoal', 'DK':'Dark', 'GD':'Gold', 'GO':'Gold',\n",
    "    'GN':'Green', 'GY':'Gray', 'GT':'Granite', 'IV':'Ivory',\n",
    "    'LT':'Light', 'OL':'Olive', 'OR':'Orange', 'MR':'Maroon',\n",
    "    'PK':'Pink', 'RD':'Red', 'RE':'Red', 'SI':'Silver', 'SL':'Silver',\n",
    "    'SM':'Smoke', 'TN':'Tan', 'VT':'Violet', 'WT':'White',\n",
    "    'WH':'White', 'YL':'Yellow', 'YE':'Yellow', 'UN':'Unknown'\n",
    "    }\n",
    "\n",
    "    if shades in COLORS:\n",
    "        return COLORS[shades]\n",
    "    else:\n",
    "        return shades\n",
    "    \n",
    "# User-defined function. Input type is a string. \n",
    "\n",
    "udf_color_long = udf(color_long, StringType())\n",
    "mapping_color = DF_float.withColumn('Color Long', udf_color_long('Color'))\n",
    "mapping_color.select('Color','Color long').show(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.9 Using this new column, what’s the most frequent colour value for Hondas (HOND)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|Color Long| count|\n",
      "+----------+------+\n",
      "|      Gray|266135|\n",
      "+----------+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HOND = mapping_color.filter(mapping_color['Make'] == 'HOND')\n",
    "HOND.groupBy('Color Long')\\\n",
    "             .count()\\\n",
    "             .sort('count', ascending=False)\\\n",
    "             .show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
